{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Warning: SQLite3 version 3.40.0 and 3.41.2 have huge performance regressions; please install version 3.41.1 or 3.42!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from modules.ontology_classes import CogafInstance\n",
    "from modules.emotion import get_senticnet_response\n",
    "from modules.engine import COGN_FUNC\n",
    "from modules.model_builder import BaseModel\n",
    "from modules.text_processing import load_text_files, get_most_important_words, get_event"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and process texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00_Caida piso mojado.txt</td>\n",
       "      <td>Lecciones Aprendidas\\n\\nAccidente de trabajo\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01_Caída de altura.txt</td>\n",
       "      <td>LECCIONES APRENDIDAS\\n\\nTipo de Accidente: Caí...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>02_ auxiliar_trafico_aprisionado_vehiculo.txt</td>\n",
       "      <td>Auxiliar de tráfico (Paletero - Señalelo) apri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>03_Caida de alturas_Lesiones Múltiples.txt</td>\n",
       "      <td>Lecciones aprendidas\\n\\nCaida de alturas \\nLes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>04_Caida_alturas_montaje_estructura.txt</td>\n",
       "      <td>LECCIONES APRENDIDAS\\n\\nCaída de alturas en mo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            file  \\\n",
       "0                       00_Caida piso mojado.txt   \n",
       "1                         01_Caída de altura.txt   \n",
       "2  02_ auxiliar_trafico_aprisionado_vehiculo.txt   \n",
       "3     03_Caida de alturas_Lesiones Múltiples.txt   \n",
       "4        04_Caida_alturas_montaje_estructura.txt   \n",
       "\n",
       "                                                text  \n",
       "0  Lecciones Aprendidas\\n\\nAccidente de trabajo\\n...  \n",
       "1  LECCIONES APRENDIDAS\\n\\nTipo de Accidente: Caí...  \n",
       "2  Auxiliar de tráfico (Paletero - Señalelo) apri...  \n",
       "3  Lecciones aprendidas\\n\\nCaida de alturas \\nLes...  \n",
       "4  LECCIONES APRENDIDAS\\n\\nCaída de alturas en mo...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_list = load_text_files('./../data/text/raw/')\n",
    "\n",
    "df = pd.DataFrame({\"file\": text_list.keys(), \"text\": text_list.values()})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load preprocess model\n",
    "import joblib\n",
    "MODELS_PATH = \"./models/\"\n",
    "processor = joblib.load(MODELS_PATH + \"preprocessor.pk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First step of processor pipeline is text cleaning. Clean text is needed for emotion recognition\n",
    "df[\"clean_text\"] = processor[0].transform(df.text)\n",
    "\n",
    "# Get TF-IDF matrix\n",
    "tfidf_matrix = processor[1].transform(df.clean_text)\n",
    "\n",
    "# Perform PCA for dimensionality reduction\n",
    "# X_pca = pd.DataFrame(processor[2:].transform(tfidf_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>2583</th>\n",
       "      <th>2584</th>\n",
       "      <th>2585</th>\n",
       "      <th>2586</th>\n",
       "      <th>2587</th>\n",
       "      <th>2588</th>\n",
       "      <th>2589</th>\n",
       "      <th>2590</th>\n",
       "      <th>2591</th>\n",
       "      <th>2592</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.069118</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2593 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0     1     2     3     4     5     6     7     8     9     ...  2583  \\\n",
       "0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "1   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "2   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "3   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "4   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "\n",
       "   2584  2585  2586  2587  2588      2589  2590  2591  2592  \n",
       "0   0.0   0.0   0.0   0.0   0.0  0.000000   0.0   0.0   0.0  \n",
       "1   0.0   0.0   0.0   0.0   0.0  0.000000   0.0   0.0   0.0  \n",
       "2   0.0   0.0   0.0   0.0   0.0  0.000000   0.0   0.0   0.0  \n",
       "3   0.0   0.0   0.0   0.0   0.0  0.000000   0.0   0.0   0.0  \n",
       "4   0.0   0.0   0.0   0.0   0.0  0.069118   0.0   0.0   0.0  \n",
       "\n",
       "[5 rows x 2593 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = pd.DataFrame(tfidf_matrix.toarray())\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cognitive Function Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup device agnostic code\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.from_numpy(X.to_numpy()).type(torch.float)\n",
    "\n",
    "in_features, out_features = X.shape[1], 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaseModel(\n",
       "  (linear_stack): Sequential(\n",
       "    (0): Linear(in_features=2593, out_features=50, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=50, out_features=5, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load model and predict cognitive function\n",
    "clf = BaseModel(in_features, 50, out_features)\n",
    "\n",
    "# Load model state dict \n",
    "clf.load_state_dict(torch.load(\"./models/mlp.pth\"))\n",
    "\n",
    "# Put model to target device (if your data is on GPU, model will have to be on GPU to make predictions)\n",
    "clf.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.eval()\n",
    "with torch.inference_mode():\n",
    "    logits = clf(X.to(device))\n",
    "    y_pred = logits.argmax(dim=1).to(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 2, 1, 2, 3, 1, 3, 2, 1, 2, 3, 2, 2, 2, 0, 0, 2, 2, 2, 0, 0, 0, 0, 2,\n",
       "        2, 1, 1, 3, 3, 1, 2, 0, 0, 0, 2, 2, 2, 0, 2, 0, 0, 0, 0, 0, 2, 2, 0, 2,\n",
       "        2, 1, 0, 2, 0, 0, 0, 1, 1, 1, 1, 1, 0, 4, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 1, 2, 2])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Attention',\n",
       " 'Perception',\n",
       " 'WorkingMemory',\n",
       " 'Perception',\n",
       " 'CognitiveFlexibility',\n",
       " 'WorkingMemory',\n",
       " 'CognitiveFlexibility',\n",
       " 'Perception',\n",
       " 'WorkingMemory',\n",
       " 'Perception',\n",
       " 'CognitiveFlexibility',\n",
       " 'Perception',\n",
       " 'Perception',\n",
       " 'Perception',\n",
       " 'Attention',\n",
       " 'Attention',\n",
       " 'Perception',\n",
       " 'Perception',\n",
       " 'Perception',\n",
       " 'Attention',\n",
       " 'Attention',\n",
       " 'Attention',\n",
       " 'Attention',\n",
       " 'Perception',\n",
       " 'Perception',\n",
       " 'WorkingMemory',\n",
       " 'WorkingMemory',\n",
       " 'CognitiveFlexibility',\n",
       " 'CognitiveFlexibility',\n",
       " 'WorkingMemory',\n",
       " 'Perception',\n",
       " 'Attention',\n",
       " 'Attention',\n",
       " 'Attention',\n",
       " 'Perception',\n",
       " 'Perception',\n",
       " 'Perception',\n",
       " 'Attention',\n",
       " 'Perception',\n",
       " 'Attention',\n",
       " 'Attention',\n",
       " 'Attention',\n",
       " 'Attention',\n",
       " 'Attention',\n",
       " 'Perception',\n",
       " 'Perception',\n",
       " 'Attention',\n",
       " 'Perception',\n",
       " 'Perception',\n",
       " 'WorkingMemory',\n",
       " 'Attention',\n",
       " 'Perception',\n",
       " 'Attention',\n",
       " 'Attention',\n",
       " 'Attention',\n",
       " 'WorkingMemory',\n",
       " 'WorkingMemory',\n",
       " 'WorkingMemory',\n",
       " 'WorkingMemory',\n",
       " 'WorkingMemory',\n",
       " 'Attention',\n",
       " 'InhibitoryControl',\n",
       " 'Attention',\n",
       " 'Attention',\n",
       " 'Attention',\n",
       " 'InhibitoryControl',\n",
       " 'Attention',\n",
       " 'Attention',\n",
       " 'Attention',\n",
       " 'Attention',\n",
       " 'Attention',\n",
       " 'Attention',\n",
       " 'Attention',\n",
       " 'Attention',\n",
       " 'Attention',\n",
       " 'WorkingMemory',\n",
       " 'Perception',\n",
       " 'Perception']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = [COGN_FUNC[i] for i in y_pred]\n",
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Emotion Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With 200 most important words as input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = processor[1].get_feature_names_out()\n",
    "tfidf_scores = tfidf_matrix.toarray()\n",
    "\n",
    "important_words_per_doc = get_most_important_words(feature_names, tfidf_scores, df.file, 200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_with_top_words = []\n",
    "for i in range(len(important_words_per_doc)):\n",
    "    result = {\"cognitive_function\": COGN_FUNC[y_pred[i]]}\n",
    "    result.update(get_senticnet_response(important_words_per_doc[i][\"words\"]))\n",
    "    results_with_top_words.append(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With entire clean text as input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for i in range(len(df.clean_text)):\n",
    "    result = {\"cognitive_function\": COGN_FUNC[y_pred[i]]}\n",
    "    result.update(get_senticnet_response(df.clean_text[i]))\n",
    "    results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cognitive_function': 'WorkingMemory',\n",
       " 'status_code': 200,\n",
       " 'content': 'ecstasy (83.65%) & calmness (31.58%) [INTROSPECTION=93.61%,TEMPER=43.42%,ATTITUDE=-3.12%,SENSITIVITY=-23.61%]\\n',\n",
       " 'introspection': {'value': 0.9361, 'emotion': 'Ecstasy'},\n",
       " 'temper': {'value': 0.43420000000000003, 'emotion': 'Calmness'},\n",
       " 'attitude': {'value': -0.031200000000000002, 'emotion': 'Dislike'},\n",
       " 'sensitivity': {'value': -0.2361, 'emotion': 'Anxiety'}}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cognitive_function': 'WorkingMemory',\n",
       " 'status_code': 200,\n",
       " 'content': 'ecstasy (75.29%) & bliss (4.81%) [INTROSPECTION=90.84%,TEMPER=67.59%,ATTITUDE=-1.27%,SENSITIVITY=-11.21%]\\n',\n",
       " 'introspection': {'value': 0.9084, 'emotion': 'Ecstasy'},\n",
       " 'temper': {'value': 0.6759000000000001, 'emotion': 'Bliss'},\n",
       " 'attitude': {'value': -0.0127, 'emotion': 'Dislike'},\n",
       " 'sensitivity': {'value': -0.1121, 'emotion': 'Anxiety'}}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_with_top_words[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ontology components inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>text</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>norm_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00_Caida piso mojado.txt</td>\n",
       "      <td>Lecciones Aprendidas\\n\\nAccidente de trabajo\\n...</td>\n",
       "      <td>leccion aprendido accidente trabajo caida piso...</td>\n",
       "      <td>Lecciones Aprendidas Accidente de trabajo Caíd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01_Caída de altura.txt</td>\n",
       "      <td>LECCIONES APRENDIDAS\\n\\nTipo de Accidente: Caí...</td>\n",
       "      <td>leccion aprendido tipo accidente caida altura ...</td>\n",
       "      <td>LECCIONES APRENDIDAS Tipo de Accidente: Caída ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>02_ auxiliar_trafico_aprisionado_vehiculo.txt</td>\n",
       "      <td>Auxiliar de tráfico (Paletero - Señalelo) apri...</td>\n",
       "      <td>auxiliar trafico paletero senalelo aprisionado...</td>\n",
       "      <td>Auxiliar de tráfico (Paletero - Señalelo) apri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>03_Caida de alturas_Lesiones Múltiples.txt</td>\n",
       "      <td>Lecciones aprendidas\\n\\nCaida de alturas \\nLes...</td>\n",
       "      <td>leccion aprendido caida altura lesion multiple...</td>\n",
       "      <td>Lecciones aprendidas Caida de alturas Lesiones...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>04_Caida_alturas_montaje_estructura.txt</td>\n",
       "      <td>LECCIONES APRENDIDAS\\n\\nCaída de alturas en mo...</td>\n",
       "      <td>leccion aprendido caida altura montaje estruct...</td>\n",
       "      <td>LECCIONES APRENDIDAS Caída de alturas en monta...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            file  \\\n",
       "0                       00_Caida piso mojado.txt   \n",
       "1                         01_Caída de altura.txt   \n",
       "2  02_ auxiliar_trafico_aprisionado_vehiculo.txt   \n",
       "3     03_Caida de alturas_Lesiones Múltiples.txt   \n",
       "4        04_Caida_alturas_montaje_estructura.txt   \n",
       "\n",
       "                                                text  \\\n",
       "0  Lecciones Aprendidas\\n\\nAccidente de trabajo\\n...   \n",
       "1  LECCIONES APRENDIDAS\\n\\nTipo de Accidente: Caí...   \n",
       "2  Auxiliar de tráfico (Paletero - Señalelo) apri...   \n",
       "3  Lecciones aprendidas\\n\\nCaida de alturas \\nLes...   \n",
       "4  LECCIONES APRENDIDAS\\n\\nCaída de alturas en mo...   \n",
       "\n",
       "                                          clean_text  \\\n",
       "0  leccion aprendido accidente trabajo caida piso...   \n",
       "1  leccion aprendido tipo accidente caida altura ...   \n",
       "2  auxiliar trafico paletero senalelo aprisionado...   \n",
       "3  leccion aprendido caida altura lesion multiple...   \n",
       "4  leccion aprendido caida altura montaje estruct...   \n",
       "\n",
       "                                           norm_text  \n",
       "0  Lecciones Aprendidas Accidente de trabajo Caíd...  \n",
       "1  LECCIONES APRENDIDAS Tipo de Accidente: Caída ...  \n",
       "2  Auxiliar de tráfico (Paletero - Señalelo) apri...  \n",
       "3  Lecciones aprendidas Caida de alturas Lesiones...  \n",
       "4  LECCIONES APRENDIDAS Caída de alturas en monta...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from modules.text_processing import normalize\n",
    "\n",
    "df['norm_text'] = [normalize(text, False, False) for text in df.text]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "events = [get_event(text) for text in df.norm_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import owlready2 as owl\n",
    "onto = owl.get_ontology(\"./../ontology/Hourglass_COGAF_Ontology.rdf\").load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_instance = onto.Emotion(\n",
    "    \"test_emotion\", \n",
    "    introspection=results_with_top_words[0][\"introspection\"][\"value\"],\n",
    "    temper=results_with_top_words[0][\"temper\"][\"value\"],\n",
    "    attitude=results_with_top_words[0][\"attitude\"][\"value\"],\n",
    "    sensitivity=results_with_top_words[0][\"sensitivity\"][\"value\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.613"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onto.test_emotion.introspection"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
