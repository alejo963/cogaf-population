{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Warning: SQLite3 version 3.40.0 and 3.41.2 have huge performance regressions; please install version 3.41.1 or 3.42!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from modules.ontology_classes import CogafInstance\n",
    "from modules.emotion import get_senticnet_response\n",
    "from modules.engine import COGN_FUNC\n",
    "from modules.text_processing import load_text_files, get_most_important_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and process texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000_000_999-accidentes-trabajo.txt</td>\n",
       "      <td>Lecciones Aprendidas\\n\\nAccidente de trabajo\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31-5_Caida_desde_escalera_de_silo.txt</td>\n",
       "      <td>LECCIONES APRENDIDAS\\n\\nTipo de Accidente: Caí...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>012015-Lecciones-aprendidas.txt</td>\n",
       "      <td>Descripción de caso\\n\\nEl 08 de octubre de 201...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>auxiliar_trafico_aprisionado_vehiculo.txt</td>\n",
       "      <td>Auxiliar de tráfico (Paletero - Señalelo) apri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>caida_alturas.txt</td>\n",
       "      <td>Lecciones aprendidas\\n\\nCaida de alturas \\nLes...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        file  \\\n",
       "0        0000_000_999-accidentes-trabajo.txt   \n",
       "1      31-5_Caida_desde_escalera_de_silo.txt   \n",
       "2            012015-Lecciones-aprendidas.txt   \n",
       "3  auxiliar_trafico_aprisionado_vehiculo.txt   \n",
       "4                          caida_alturas.txt   \n",
       "\n",
       "                                                text  \n",
       "0  Lecciones Aprendidas\\n\\nAccidente de trabajo\\n...  \n",
       "1  LECCIONES APRENDIDAS\\n\\nTipo de Accidente: Caí...  \n",
       "2  Descripción de caso\\n\\nEl 08 de octubre de 201...  \n",
       "3  Auxiliar de tráfico (Paletero - Señalelo) apri...  \n",
       "4  Lecciones aprendidas\\n\\nCaida de alturas \\nLes...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_list = load_text_files('./../data/text/raw/')\n",
    "\n",
    "df = pd.DataFrame({\"file\": text_list.keys(), \"text\": text_list.values()})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load preprocess model\n",
    "import joblib\n",
    "MODELS_PATH = \"./models/\"\n",
    "processor = joblib.load(MODELS_PATH + \"preprocessor.pk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First step of processor pipeline is text cleaning. Clean text is needed for emotion recognition\n",
    "df[\"clean_text\"] = processor[0].transform(df.text)\n",
    "\n",
    "# Get TF-IDF matrix\n",
    "tfidf_matrix = processor[1].transform(df.clean_text)\n",
    "\n",
    "# Perform PCA for dimensionality reduction\n",
    "X = pd.DataFrame(processor[2:].transform(tfidf_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "      <th>64</th>\n",
       "      <th>65</th>\n",
       "      <th>66</th>\n",
       "      <th>67</th>\n",
       "      <th>68</th>\n",
       "      <th>69</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.018390</td>\n",
       "      <td>0.153832</td>\n",
       "      <td>-0.036187</td>\n",
       "      <td>-0.096114</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.008908</td>\n",
       "      <td>0.025292</td>\n",
       "      <td>-0.015457</td>\n",
       "      <td>-0.002550</td>\n",
       "      <td>0.051419</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004520</td>\n",
       "      <td>-0.021593</td>\n",
       "      <td>0.034531</td>\n",
       "      <td>0.036302</td>\n",
       "      <td>0.009767</td>\n",
       "      <td>-0.002026</td>\n",
       "      <td>-0.014995</td>\n",
       "      <td>-0.014123</td>\n",
       "      <td>-0.044726</td>\n",
       "      <td>-0.007895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.026766</td>\n",
       "      <td>0.421393</td>\n",
       "      <td>-0.068882</td>\n",
       "      <td>0.105197</td>\n",
       "      <td>0.042154</td>\n",
       "      <td>0.029687</td>\n",
       "      <td>0.110361</td>\n",
       "      <td>-0.105812</td>\n",
       "      <td>-0.130303</td>\n",
       "      <td>0.160647</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005570</td>\n",
       "      <td>-0.002325</td>\n",
       "      <td>-0.000482</td>\n",
       "      <td>-0.014414</td>\n",
       "      <td>-0.022651</td>\n",
       "      <td>-0.008666</td>\n",
       "      <td>-0.001102</td>\n",
       "      <td>0.011631</td>\n",
       "      <td>-0.002150</td>\n",
       "      <td>0.002202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.011969</td>\n",
       "      <td>0.184345</td>\n",
       "      <td>-0.021444</td>\n",
       "      <td>-0.121609</td>\n",
       "      <td>-0.055329</td>\n",
       "      <td>-0.001112</td>\n",
       "      <td>0.375440</td>\n",
       "      <td>-0.127316</td>\n",
       "      <td>-0.151340</td>\n",
       "      <td>-0.158765</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004352</td>\n",
       "      <td>0.011736</td>\n",
       "      <td>0.001587</td>\n",
       "      <td>0.005040</td>\n",
       "      <td>0.001057</td>\n",
       "      <td>0.003236</td>\n",
       "      <td>0.006027</td>\n",
       "      <td>-0.008859</td>\n",
       "      <td>-0.001709</td>\n",
       "      <td>0.000355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.081711</td>\n",
       "      <td>0.261403</td>\n",
       "      <td>-0.040354</td>\n",
       "      <td>-0.218305</td>\n",
       "      <td>0.017647</td>\n",
       "      <td>-0.012647</td>\n",
       "      <td>0.264102</td>\n",
       "      <td>0.090078</td>\n",
       "      <td>-0.115739</td>\n",
       "      <td>-0.180781</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002372</td>\n",
       "      <td>-0.005515</td>\n",
       "      <td>0.006456</td>\n",
       "      <td>0.006268</td>\n",
       "      <td>-0.002655</td>\n",
       "      <td>-0.004133</td>\n",
       "      <td>-0.000517</td>\n",
       "      <td>0.003722</td>\n",
       "      <td>0.007989</td>\n",
       "      <td>0.005342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.051404</td>\n",
       "      <td>0.201853</td>\n",
       "      <td>-0.044697</td>\n",
       "      <td>-0.084711</td>\n",
       "      <td>0.000786</td>\n",
       "      <td>0.010653</td>\n",
       "      <td>0.172421</td>\n",
       "      <td>-0.080946</td>\n",
       "      <td>-0.096627</td>\n",
       "      <td>0.077496</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.011919</td>\n",
       "      <td>-0.002356</td>\n",
       "      <td>-0.002698</td>\n",
       "      <td>-0.006592</td>\n",
       "      <td>-0.002185</td>\n",
       "      <td>-0.009310</td>\n",
       "      <td>0.006778</td>\n",
       "      <td>-0.018198</td>\n",
       "      <td>-0.016595</td>\n",
       "      <td>0.014457</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 70 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6   \\\n",
       "0  0.018390  0.153832 -0.036187 -0.096114  0.000189  0.008908  0.025292   \n",
       "1 -0.026766  0.421393 -0.068882  0.105197  0.042154  0.029687  0.110361   \n",
       "2  0.011969  0.184345 -0.021444 -0.121609 -0.055329 -0.001112  0.375440   \n",
       "3 -0.081711  0.261403 -0.040354 -0.218305  0.017647 -0.012647  0.264102   \n",
       "4 -0.051404  0.201853 -0.044697 -0.084711  0.000786  0.010653  0.172421   \n",
       "\n",
       "         7         8         9   ...        60        61        62        63  \\\n",
       "0 -0.015457 -0.002550  0.051419  ...  0.004520 -0.021593  0.034531  0.036302   \n",
       "1 -0.105812 -0.130303  0.160647  ...  0.005570 -0.002325 -0.000482 -0.014414   \n",
       "2 -0.127316 -0.151340 -0.158765  ...  0.004352  0.011736  0.001587  0.005040   \n",
       "3  0.090078 -0.115739 -0.180781  ... -0.002372 -0.005515  0.006456  0.006268   \n",
       "4 -0.080946 -0.096627  0.077496  ... -0.011919 -0.002356 -0.002698 -0.006592   \n",
       "\n",
       "         64        65        66        67        68        69  \n",
       "0  0.009767 -0.002026 -0.014995 -0.014123 -0.044726 -0.007895  \n",
       "1 -0.022651 -0.008666 -0.001102  0.011631 -0.002150  0.002202  \n",
       "2  0.001057  0.003236  0.006027 -0.008859 -0.001709  0.000355  \n",
       "3 -0.002655 -0.004133 -0.000517  0.003722  0.007989  0.005342  \n",
       "4 -0.002185 -0.009310  0.006778 -0.018198 -0.016595  0.014457  \n",
       "\n",
       "[5 rows x 70 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = processor[1].get_feature_names_out()\n",
    "tfidf_scores = tfidf_matrix.toarray()\n",
    "\n",
    "important_words_per_doc = get_most_important_words(feature_names, tfidf_scores, df.file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'doc': '0000_000_999-accidentes-trabajo.txt',\n",
       " 'words': 'piso, trabajo, companero, mojado, evitar, senalizacion, limpieza, caida, contribuir, limpio, suela, verter, comunicacion, utilizar, causo, generara, liquido, objetivo, antideslizante, organizacional, comunicar, guarda, nuevamente, antebrazo, codo, elemento, limpiar, madera, accidente, alcance'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "important_words_per_doc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status_code': 200,\n",
       " 'content': 'ecstasy (66.66%) & delight (50.87%) [INTROSPECTION=88.0%,TEMPER=-1.05%,ATTITUDE=82.79%,SENSITIVITY=-48.0%]\\n',\n",
       " 'introspection': {'value': 0.88, 'emotion': 'Ecstasy'},\n",
       " 'temper': {'value': -0.0105, 'emotion': 'Annoyance'},\n",
       " 'attitude': {'value': 0.8279000000000001, 'emotion': 'Delight'},\n",
       " 'sensitivity': {'value': -0.48, 'emotion': 'Fear'}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_senticnet_response(important_words_per_doc[0][\"words\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cognitive Function Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
       "       6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
       "       6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
       "       6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
       "       6], dtype=int64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load model and predict cognitive function\n",
    "clf = joblib.load(MODELS_PATH + \"svm.pk\")\n",
    "y_pred = clf.predict(X)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Emotion Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for i in range(len(df.clean_text)):\n",
    "    result = {\"cognitive_function\": COGN_FUNC[y_pred[i]]}\n",
    "    result.update(get_senticnet_response(df.clean_text[i]))\n",
    "    results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cognitive_function': 'Praxia',\n",
       " 'status_code': 200,\n",
       " 'content': 'ecstasy (78.33%) & calmness (95.35%) [INTROSPECTION=91.85%,TEMPER=64.46%,ATTITUDE=-3.0%,SENSITIVITY=-7.1%]\\n',\n",
       " 'introspection': {'value': 0.9185, 'emotion': 'Ecstasy'},\n",
       " 'temper': {'value': 0.6446, 'emotion': 'Calmness'},\n",
       " 'attitude': {'value': -0.03, 'emotion': 'Dislike'},\n",
       " 'sensitivity': {'value': -0.071, 'emotion': 'Anxiety'}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ontology components inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Get strongest emotion(s) and map to basic emotion model\n",
    "\n",
    "for result in results:\n",
    "    if result[\"status_code\"] == 200:\n",
    "        result.update({\"cogaf_instance\": CogafInstance(result[\"cognitive_function\"], result[\"sensitivity\"][\"emotion\"])})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'Praxia',\n",
       " 'isBasicFunction': False,\n",
       " 'activities': [<modules.ontology_classes.ComplementaryActivity at 0x25b27331710>],\n",
       " 'tasks': []}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[2][\"cogaf_instance\"].cognitiveFunction.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cognitiveFunction': {'name': 'Praxia',\n",
       "  'isBasicFunction': False,\n",
       "  'activities': [{'name': 'Karaoke', 'mechanics': ['Match', 'Vocalize']}],\n",
       "  'tasks': []},\n",
       " 'emotion': {'name': 'Eagerness', 'isBasicEmotion': None, 'state': None}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[2][\"cogaf_instance\"].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
