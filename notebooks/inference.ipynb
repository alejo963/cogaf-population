{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Warning: SQLite3 version 3.40.0 and 3.41.2 have huge performance regressions; please install version 3.41.1 or 3.42!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from modules.ontology_classes import CogafInstance, set_ontology\n",
    "from modules.emotion import get_senticnet_response\n",
    "from modules.engine import COGN_FUNC\n",
    "from modules.model_builder import BaseModel\n",
    "from modules.text_processing import load_text_files, get_most_important_words, get_event, get_capabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and process texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00_Caida piso mojado.txt</td>\n",
       "      <td>Lecciones Aprendidas\\n\\nAccidente de trabajo\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01_Caída de altura.txt</td>\n",
       "      <td>LECCIONES APRENDIDAS\\n\\nTipo de Accidente: Caí...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>02_ auxiliar_trafico_aprisionado_vehiculo.txt</td>\n",
       "      <td>Auxiliar de tráfico (Paletero - Señalelo) apri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>03_Caida de alturas_Lesiones Múltiples.txt</td>\n",
       "      <td>Lecciones aprendidas\\n\\nCaida de alturas \\nLes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>04_Caida_alturas_montaje_estructura.txt</td>\n",
       "      <td>LECCIONES APRENDIDAS\\n\\nCaída de alturas en mo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            file  \\\n",
       "0                       00_Caida piso mojado.txt   \n",
       "1                         01_Caída de altura.txt   \n",
       "2  02_ auxiliar_trafico_aprisionado_vehiculo.txt   \n",
       "3     03_Caida de alturas_Lesiones Múltiples.txt   \n",
       "4        04_Caida_alturas_montaje_estructura.txt   \n",
       "\n",
       "                                                text  \n",
       "0  Lecciones Aprendidas\\n\\nAccidente de trabajo\\n...  \n",
       "1  LECCIONES APRENDIDAS\\n\\nTipo de Accidente: Caí...  \n",
       "2  Auxiliar de tráfico (Paletero - Señalelo) apri...  \n",
       "3  Lecciones aprendidas\\n\\nCaida de alturas \\nLes...  \n",
       "4  LECCIONES APRENDIDAS\\n\\nCaída de alturas en mo...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_list = load_text_files('./../data/text/raw/')\n",
    "\n",
    "df = pd.DataFrame({\"file\": text_list.keys(), \"text\": text_list.values()})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load preprocess model\n",
    "import joblib\n",
    "MODELS_PATH = \"./models/\"\n",
    "processor = joblib.load(MODELS_PATH + \"preprocessor.pk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First step of processor pipeline is text cleaning. Clean text is needed for emotion recognition\n",
    "df[\"clean_text\"] = processor[0].transform(df.text)\n",
    "\n",
    "# Get TF-IDF matrix\n",
    "tfidf_matrix = processor[1].transform(df.clean_text)\n",
    "\n",
    "# Perform PCA for dimensionality reduction\n",
    "# X_pca = pd.DataFrame(processor[2:].transform(tfidf_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>2583</th>\n",
       "      <th>2584</th>\n",
       "      <th>2585</th>\n",
       "      <th>2586</th>\n",
       "      <th>2587</th>\n",
       "      <th>2588</th>\n",
       "      <th>2589</th>\n",
       "      <th>2590</th>\n",
       "      <th>2591</th>\n",
       "      <th>2592</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.069118</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2593 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0     1     2     3     4     5     6     7     8     9     ...  2583  \\\n",
       "0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "1   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "2   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "3   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "4   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "\n",
       "   2584  2585  2586  2587  2588      2589  2590  2591  2592  \n",
       "0   0.0   0.0   0.0   0.0   0.0  0.000000   0.0   0.0   0.0  \n",
       "1   0.0   0.0   0.0   0.0   0.0  0.000000   0.0   0.0   0.0  \n",
       "2   0.0   0.0   0.0   0.0   0.0  0.000000   0.0   0.0   0.0  \n",
       "3   0.0   0.0   0.0   0.0   0.0  0.000000   0.0   0.0   0.0  \n",
       "4   0.0   0.0   0.0   0.0   0.0  0.069118   0.0   0.0   0.0  \n",
       "\n",
       "[5 rows x 2593 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = pd.DataFrame(tfidf_matrix.toarray())\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cognitive Function Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup device agnostic code\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.from_numpy(X.to_numpy()).type(torch.float)\n",
    "\n",
    "in_features, out_features = X.shape[1], 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaseModel(\n",
       "  (linear_stack): Sequential(\n",
       "    (0): Linear(in_features=2593, out_features=50, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=50, out_features=5, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load model and predict cognitive function\n",
    "clf = BaseModel(in_features, 50, out_features)\n",
    "\n",
    "# Load model state dict \n",
    "clf.load_state_dict(torch.load(\"./models/mlp.pth\"))\n",
    "\n",
    "# Put model to target device (if your data is on GPU, model will have to be on GPU to make predictions)\n",
    "clf.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.eval()\n",
    "with torch.inference_mode():\n",
    "    logits = clf(X.to(device))\n",
    "    y_pred = logits.argmax(dim=1).to(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 2, 1, 2, 3, 1, 3, 2, 1, 2, 3, 2, 2, 2, 0, 0, 2, 2, 2, 0, 0, 0, 0, 2,\n",
       "        2, 1, 1, 3, 3, 1, 2, 0, 0, 0, 2, 2, 2, 0, 2, 0, 0, 0, 0, 0, 2, 2, 0, 2,\n",
       "        2, 1, 0, 2, 0, 0, 0, 1, 1, 1, 1, 1, 0, 4, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 1, 2, 2])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Attention',\n",
       " 'Perception',\n",
       " 'WorkingMemory',\n",
       " 'Perception',\n",
       " 'CognitiveFlexibility']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = [COGN_FUNC[i] for i in y_pred]\n",
    "pred[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Emotion Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With 150 most important words as input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'doc': '00_Caida piso mojado.txt',\n",
       " 'words': 'piso companero mojado trabajo limpieza caida senalizacion comunicacion evitar alcance antebrazo antideslizante asertivo camin codo contribuir escoba evidenciado fluido funcionario generara limpiar liquido meta nuevamente regresara removedor suela trapero ugc universidad vea verter utilizar espalda mirar accidente elemento bajar causo guarda objetivo advertencia comunicar continuar organizacional cabeza limpio prestar encontrar desplazamiento direccion ocurrir reportar peligro ausencia calzado ocurrencia realizar deber madera paso realizacion actividad golpe mantener ocasionar cumplimiento ubicado labor verificar proteccion condicion momento instalacion adecuado desarrollo atencion inseguro falta pasar consecuencia leccion personal aprendido 00 000 009 0099 00pm 03 030 0312 04 05 055 07 08 09 10 100 1000 103 106 1072 108 11 1100 118 12 120 123 13 13200 14 1401 1409 141 142 146 15 16 164 17 170 171 175 18 180 182 187 1886 19 1950 20 200 2001 2007 2012 2014 2015 2017 2018 2019 2020 2021 2022 21 22 220'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names = processor[1].get_feature_names_out()\n",
    "tfidf_scores = tfidf_matrix.toarray()\n",
    "\n",
    "important_words_per_doc = get_most_important_words(feature_names, tfidf_scores, df.file, 150)\n",
    "important_words_per_doc[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'file': '05_Caida_trabajador_foso_ascensor.txt',\n",
       " 'cognitive_function': 'WorkingMemory',\n",
       " 'emotion': {'status_code': 200,\n",
       "  'content': 'ecstasy (75.29%) & bliss (4.81%) [INTROSPECTION=90.84%,TEMPER=67.59%,ATTITUDE=-1.27%,SENSITIVITY=-11.21%]\\n',\n",
       "  'introspection': {'value': 0.9084, 'emotion': 'Ecstasy'},\n",
       "  'temper': {'value': 0.6759000000000001, 'emotion': 'Bliss'},\n",
       "  'attitude': {'value': -0.0127, 'emotion': 'Dislike'},\n",
       "  'sensitivity': {'value': -0.1121, 'emotion': 'Anxiety'}}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_with_top_words = []\n",
    "for i in range(len(important_words_per_doc)):\n",
    "    result = {\"file\": important_words_per_doc[i][\"doc\"],\n",
    "              \"cognitive_function\": COGN_FUNC[y_pred[i]]}\n",
    "    \n",
    "    result.update({\"emotion\": get_senticnet_response(\n",
    "        important_words_per_doc[i][\"words\"])})\n",
    "\n",
    "    results_with_top_words.append(result)\n",
    "\n",
    "results_with_top_words[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With entire clean text as input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results = []\n",
    "# for i in range(len(df.clean_text)):\n",
    "#     result = {\"cognitive_function\": COGN_FUNC[y_pred[i]]}\n",
    "#     result.update(get_senticnet_response(df.clean_text[i]))\n",
    "#     results.append(result)\n",
    "# results[5]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Event and Capabilites extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>text</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>norm_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00_Caida piso mojado.txt</td>\n",
       "      <td>Lecciones Aprendidas\\n\\nAccidente de trabajo\\n...</td>\n",
       "      <td>leccion aprendido accidente trabajo caida piso...</td>\n",
       "      <td>Lecciones Aprendidas Accidente de trabajo Caíd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01_Caída de altura.txt</td>\n",
       "      <td>LECCIONES APRENDIDAS\\n\\nTipo de Accidente: Caí...</td>\n",
       "      <td>leccion aprendido tipo accidente caida altura ...</td>\n",
       "      <td>LECCIONES APRENDIDAS Tipo de Accidente: Caída ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>02_ auxiliar_trafico_aprisionado_vehiculo.txt</td>\n",
       "      <td>Auxiliar de tráfico (Paletero - Señalelo) apri...</td>\n",
       "      <td>auxiliar trafico paletero senalelo aprisionado...</td>\n",
       "      <td>Auxiliar de tráfico (Paletero - Señalelo) apri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>03_Caida de alturas_Lesiones Múltiples.txt</td>\n",
       "      <td>Lecciones aprendidas\\n\\nCaida de alturas \\nLes...</td>\n",
       "      <td>leccion aprendido caida altura lesion multiple...</td>\n",
       "      <td>Lecciones aprendidas Caida de alturas Lesiones...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>04_Caida_alturas_montaje_estructura.txt</td>\n",
       "      <td>LECCIONES APRENDIDAS\\n\\nCaída de alturas en mo...</td>\n",
       "      <td>leccion aprendido caida altura montaje estruct...</td>\n",
       "      <td>LECCIONES APRENDIDAS Caída de alturas en monta...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            file  \\\n",
       "0                       00_Caida piso mojado.txt   \n",
       "1                         01_Caída de altura.txt   \n",
       "2  02_ auxiliar_trafico_aprisionado_vehiculo.txt   \n",
       "3     03_Caida de alturas_Lesiones Múltiples.txt   \n",
       "4        04_Caida_alturas_montaje_estructura.txt   \n",
       "\n",
       "                                                text  \\\n",
       "0  Lecciones Aprendidas\\n\\nAccidente de trabajo\\n...   \n",
       "1  LECCIONES APRENDIDAS\\n\\nTipo de Accidente: Caí...   \n",
       "2  Auxiliar de tráfico (Paletero - Señalelo) apri...   \n",
       "3  Lecciones aprendidas\\n\\nCaida de alturas \\nLes...   \n",
       "4  LECCIONES APRENDIDAS\\n\\nCaída de alturas en mo...   \n",
       "\n",
       "                                          clean_text  \\\n",
       "0  leccion aprendido accidente trabajo caida piso...   \n",
       "1  leccion aprendido tipo accidente caida altura ...   \n",
       "2  auxiliar trafico paletero senalelo aprisionado...   \n",
       "3  leccion aprendido caida altura lesion multiple...   \n",
       "4  leccion aprendido caida altura montaje estruct...   \n",
       "\n",
       "                                           norm_text  \n",
       "0  Lecciones Aprendidas Accidente de trabajo Caíd...  \n",
       "1  LECCIONES APRENDIDAS Tipo de Accidente: Caída ...  \n",
       "2  Auxiliar de tráfico (Paletero - Señalelo) apri...  \n",
       "3  Lecciones aprendidas Caida de alturas Lesiones...  \n",
       "4  LECCIONES APRENDIDAS Caída de alturas en monta...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from modules.text_processing import normalize\n",
    "\n",
    "df['norm_text'] = [normalize(text, False, False) for text in df.text]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df.norm_text)):\n",
    "    results_with_top_words[i].update({\"event\": get_event(df.norm_text[i])})\n",
    "    results_with_top_words[i].update({\"capabilities\": get_capabilities(df.norm_text[i])})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'file': '00_Caida piso mojado.txt',\n",
       " 'cognitive_function': 'Attention',\n",
       " 'emotion': {'status_code': 200,\n",
       "  'content': 'delight (24.92%) & serenity (-61.21%) [INTROSPECTION=-61.3%,TEMPER=-20.2%,ATTITUDE=74.22%,SENSITIVITY=-48.0%]\\n',\n",
       "  'introspection': {'value': -0.613, 'emotion': 'Sadness'},\n",
       "  'temper': {'value': -0.20199999999999999, 'emotion': 'Annoyance'},\n",
       "  'attitude': {'value': 0.7422, 'emotion': 'Delight'},\n",
       "  'sensitivity': {'value': -0.48, 'emotion': 'Fear'}},\n",
       " 'event': '¿Qué pasó? Un funcionario de la UGC y su compañero de trabajo se encontraban realizando la limpieza de un piso de madera en las instalaciones de la Universidad. Mientras uno de ellos bajaba al primer piso por un trapero limpio, su compañero de trabajo vertió removedor en los guarda- escobas, ocasionando que el desplazamiento del líquido generara un peligro de caída al momento en que este regresara para continuar la actividad de limpieza.',\n",
       " 'capabilities': ['comunicación']}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_with_top_words[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import owlready2 as owl\n",
    "\n",
    "onto = owl.get_ontology(\"./../ontology/Hourglass_COGAF_Ontology.rdf\").load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "instance = results_with_top_words[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_ontology(onto)\n",
    "\n",
    "for input_dict in results_with_top_words:\n",
    "    cogaf_object = CogafInstance(input_dict)\n",
    "    cogaf_object.populate_ontology()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Hourglass_COGAF_Ontology.Capability, Hourglass_COGAF_Ontology.Comunicate, Hourglass_COGAF_Ontology.Focusing, Hourglass_COGAF_Ontology.Remember, Hourglass_COGAF_Ontology.ComprehendEmotions, Hourglass_COGAF_Ontology.ProcessVisualInfo, Hourglass_COGAF_Ontology.comunicación, Hourglass_COGAF_Ontology.fracción, Hourglass_COGAF_Ontology.evaluación, Hourglass_COGAF_Ontology.supervisión, Hourglass_COGAF_Ontology.identificación, Hourglass_COGAF_Ontology.contar, Hourglass_COGAF_Ontology.seguimiento, Hourglass_COGAF_Ontology.control, Hourglass_COGAF_Ontology.planeación, Hourglass_COGAF_Ontology.planificación, Hourglass_COGAF_Ontology.inspección, Hourglass_COGAF_Ontology.evacuación, Hourglass_COGAF_Ontology.relación, Hourglass_COGAF_Ontology.concentración, Hourglass_COGAF_Ontology.clasificación, Hourglass_COGAF_Ontology.acción, Hourglass_COGAF_Ontology.reducción, Hourglass_COGAF_Ontology.confianza, Hourglass_COGAF_Ontology.lección, Hourglass_COGAF_Ontology.autocuidado, Hourglass_COGAF_Ontology.supervise, Hourglass_COGAF_Ontology.reacción, Hourglass_COGAF_Ontology.evalue, Hourglass_COGAF_Ontology.evacuar, Hourglass_COGAF_Ontology.auto-cuidado, Hourglass_COGAF_Ontology.centro, Hourglass_COGAF_Ontology.seguidir, Hourglass_COGAF_Ontology.comunicar él, Hourglass_COGAF_Ontology.clasificar, Hourglass_COGAF_Ontology.orientación, Hourglass_COGAF_Ontology.evalué, Hourglass_COGAF_Ontology.orientir, Hourglass_COGAF_Ontology.plantación, Hourglass_COGAF_Ontology.evolución, Hourglass_COGAF_Ontology.lanzar]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onto.search(is_a=onto.Capability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Hourglass_COGAF_Ontology.Event, Hourglass_COGAF_Ontology.00_Caida piso mojado, Hourglass_COGAF_Ontology.01_Caída de altura, Hourglass_COGAF_Ontology.02_ auxiliar_trafico_aprisionado_vehiculo, Hourglass_COGAF_Ontology.03_Caida de alturas_Lesiones Múltiples, Hourglass_COGAF_Ontology.04_Caida_alturas_montaje_estructura, Hourglass_COGAF_Ontology.05_Caida_trabajador_foso_ascensor, Hourglass_COGAF_Ontology.12_Explosión mina subterranea de carbón_samaca_boyaca_4_febrero_2022, Hourglass_COGAF_Ontology.13_Explosión mina subterranea de carbón_tasco_Boyaca_26_02_2022, Hourglass_COGAF_Ontology.14_Explosion_mina mestiza_el zulia_NS_20-05-2021, Hourglass_COGAF_Ontology.20_Accidente por inundacion_socota_boyaca_19_04_2017, Hourglass_COGAF_Ontology.21_Accidente minero electrico_Barrancas_Guajira_2017, Hourglass_COGAF_Ontology.22_Accidente minero electrico_Socha_Boyaca_2018, Hourglass_COGAF_Ontology.23_Accidente minero por Inundacion _Amaga_Antioquia__2014, Hourglass_COGAF_Ontology.24_Accidente minero electrico_Chivata_Boyaca_2020, Hourglass_COGAF_Ontology.26_Accidente minero por derrumbe_lenguazaque_cundinamarca_13_12_2018, Hourglass_COGAF_Ontology.27_Accidente minero por derrumbe_San Cayetano_Norte de Santander_24_02_2020, Hourglass_COGAF_Ontology.28_Accidente minero por derrumbe_Socha_Boyaca_2020, Hourglass_COGAF_Ontology.29_Accidente minero por derrumbe_Sogamoso_Boyaca_2019, Hourglass_COGAF_Ontology.31_Accidente minero por derrumbe_Vetas_Santander_2017, Hourglass_COGAF_Ontology.32_Accidente minero por derrumbre_Cali_Valle del Cauca_2018, Hourglass_COGAF_Ontology.33_Accidente minero por derrumbre_Carmen_Atrato_Choco_07_07_2018, Hourglass_COGAF_Ontology.36_Accidente minero _explocion_sub_carbon_Buenos_Aires_Cauca_2019, Hourglass_COGAF_Ontology.37_Accidente minero_exploción_sub_carbon_Cucunuba_Cundinamarca_2019, Hourglass_COGAF_Ontology.38_Accidente minero _explo_sub_carbon_Cucunuba_Cundinamarca_2020, Hourglass_COGAF_Ontology.39_Accidente minero _explosión_sub_carbon_El_Zulia_Norte de Santander_2019, Hourglass_COGAF_Ontology.40_Accidente minero_explosion_sub_carbon_Jerico_Boyaca_2017, Hourglass_COGAF_Ontology.41_Accidente minero_explosión_sub_carbon_Samaca_Boyaca_08_03_2018, Hourglass_COGAF_Ontology.42_Explosión_sub_carbon_Samaca_Boyaca_2015, Hourglass_COGAF_Ontology.43_Accidente minero_sub_carbon_Samaca_Boyaca_2018, Hourglass_COGAF_Ontology.44_Accidente minero__explo_sub_carbon_San_Cayetano_Norte de Santander_2019, Hourglass_COGAF_Ontology.45_Accidente minero_explosión_sub_carbon_Sardinata_Norte de Santander_10_12_2019, Hourglass_COGAF_Ontology.46_Accidente minero_explosión_sub_carbon_Sardinata_Norte de Santander_11_12_2019, Hourglass_COGAF_Ontology.47_Accidente minero_explosión_sub_carbon_Sardinata_Norte de Santander_2018, Hourglass_COGAF_Ontology.48_Accidente minero_explosión_sub_carbon_Sardinata_Norte de Santander_2019, Hourglass_COGAF_Ontology.49_Accidente minero_explosión _sub_carbon_Socha_Boyaca_06_12_2019, Hourglass_COGAF_Ontology.50_Accidente minero_explosión_sub_carbon_Socha_Boyaca_26_07_2019, Hourglass_COGAF_Ontology.51_Accidente minero_explosión_sub_carbon_Socha_Boyaca_29_03_2020, Hourglass_COGAF_Ontology.53_Accidente minero_explosión_sub_carbon_Socha_Boyaca_2019, Hourglass_COGAF_Ontology.52_Accidente minero_explosión_sub_carbon_Socha_Boyaca_2020, Hourglass_COGAF_Ontology.54_Accidente minero_explosión_sub_carbon_Socota_Boyaca_2017, Hourglass_COGAF_Ontology.55_Accidente minero_explosión_sub_carbon_Tasco_Boyaca_24_04_2018, Hourglass_COGAF_Ontology.56_Accidente minero_explosión_sub_carbon_Tausa_Cundinamrca_23_05_2018, Hourglass_COGAF_Ontology.57_Accidente minero_explosión_sub_carbon_Toledo_Norte de Santander_07_02_2018, Hourglass_COGAF_Ontology.58_Accidente minero_explosión_sub_carbon_Topaga_Boyaca_2019, Hourglass_COGAF_Ontology.59_Accidente minero_explosión_sub_carbon_Ventaquemada_Boyaca_2017, Hourglass_COGAF_Ontology.60_Accidente minero_explosión_sub_oro_Almaguer_Cauca_2019, Hourglass_COGAF_Ontology.61_Accidente minero _explosión_sub_oro_El_Tambo_Cauca_2019, Hourglass_COGAF_Ontology.62_Accidente minero_explosión_subterranea_carbon_Cucunuba_Cundinamarca_2017, Hourglass_COGAF_Ontology.63_Accidente minero_Caida de Roca_derrumbe_Marmato_Caldas_2018, Hourglass_COGAF_Ontology.64_Accidente minero_derrumbe_Boavita_21_04_2021, Hourglass_COGAF_Ontology.65_Accidente minero_derrumbe_Cúcuta_13_04_2021, Hourglass_COGAF_Ontology.66_ Accidente minero_explosion_San Miguel_23_10_2020, Hourglass_COGAF_Ontology.67_Accidente_choque_CUARTO SEMESTRE 2019-4-6, Hourglass_COGAF_Ontology.73_Accidente_pisada en falso_Contaduria General Nacion_2017-4, Hourglass_COGAF_Ontology.77_Accidente por caida de altura_fasecolda_Febrero 2016, Hourglass_COGAF_Ontology.06_Corte de dedos, Hourglass_COGAF_Ontology.07_Contacto con cuchillas (fresa)_Carpintero, Hourglass_COGAF_Ontology.08_Corte de pie_Albañil, Hourglass_COGAF_Ontology.09_Cogido entre la cuchilla y troquel molino máquina Termo-formadora, Hourglass_COGAF_Ontology.10_Corte con disco de motoguadaña, Hourglass_COGAF_Ontology.11_Desplazamiento en su jornada laboral_Contacto por cuerpo cortante (machete), Hourglass_COGAF_Ontology.15_Golpe contra elementos puesto trabajo_pag2, Hourglass_COGAF_Ontology.16_Caida personas_pag3, Hourglass_COGAF_Ontology.17_Caida personas_pag4, Hourglass_COGAF_Ontology.18_Contacto con paciente positivo COVID-19_pag 5, Hourglass_COGAF_Ontology.19_Caída pesronas_puesto trabajo_pag 6, Hourglass_COGAF_Ontology.68_ Accidente por escalon humedo_caida_CUARTO SEMESTRE 2019-7-9, Hourglass_COGAF_Ontology.72_ Accidente por resbalamiento_CUARTO SEMESTRE 2019-20-22, Hourglass_COGAF_Ontology.70_Accidente por lesion pie derecho_CUARTO SEMESTRE 2019-14-16, Hourglass_COGAF_Ontology.69_Accidente por lesión_CUARTO SEMESTRE 2019-10-12, Hourglass_COGAF_Ontology.71_Accidente por deslizamiento_CUARTO SEMESTRE 2019-17-19, Hourglass_COGAF_Ontology.75_Accidente ractura en la falange_Contaduria General de la Nación 2017-6, Hourglass_COGAF_Ontology.74_Accidente deslizamiento_Contaduria General de la Nación_2017-5, Hourglass_COGAF_Ontology.76_Accidente por caida_Contaduria General de la Nación_2017-7, Hourglass_COGAF_Ontology.25_Accidente minero por derrumbe_Cucuta_Norte de Santander_01_07_2017, Hourglass_COGAF_Ontology.30_Accidente mienro por derrumbe_Tasco_Boyaca_2017, Hourglass_COGAF_Ontology.34_Accidente minero por derrumbre_Cucuta_Norte_Santander_2018, Hourglass_COGAF_Ontology.35_Accidente minero_explocion_metano_polvo_carbon_Corrales_Boyaca_2017]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onto.search(is_a=onto.Event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7422"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onto.search(is_a=onto.Emotion)[1].attitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "* Owlready2 * Running HermiT...\n",
      "    C:\\java\\java-21\\jdk-21.0.2\\bin\\java.exe -Xmx2000M -cp c:\\Users\\alejo\\anaconda3\\Lib\\site-packages\\owlready2\\hermit;c:\\Users\\alejo\\anaconda3\\Lib\\site-packages\\owlready2\\hermit\\HermiT.jar org.semanticweb.HermiT.cli.CommandLine -c -O -D -I file:///C:/Users/alejo/AppData/Local/Temp/tmpfe6wnyqi\n",
      "* Owlready2 * HermiT took 1.5726327896118164 seconds\n",
      "* Owlready * (NB: only changes on entities loaded in Python are shown, other changes are done but not listed)\n"
     ]
    }
   ],
   "source": [
    "import owlready2\n",
    "from owlready2 import sync_reasoner, OwlReadyInconsistentOntologyError\n",
    "\n",
    "owlready2.JAVA_EXE = r\"C:\\java\\java-21\\jdk-21.0.2\\bin\\java.exe\"  # Path to java\n",
    "\n",
    "try:\n",
    "    with onto:\n",
    "        sync_reasoner()\n",
    "except OwlReadyInconsistentOntologyError:\n",
    "    print(\"Error! Incosistent ontology.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "onto.save(\"./output/Populated_Ontology.rdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hourglass_COGAF_Ontology'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onto.name"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
