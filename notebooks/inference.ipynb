{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Warning: SQLite3 version 3.40.0 and 3.41.2 have huge performance regressions; please install version 3.41.1 or 3.42!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from modules.ontology_classes import CogafInstance\n",
    "from modules.emotion import get_senticnet_response\n",
    "from modules.engine import COGN_FUNC\n",
    "from modules.text_processing import load_text_files, get_most_important_words, get_event"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and process texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>leccion_aprendida_explo_sub_carbon_el_zulia_nt...</td>\n",
       "      <td>LECCIÓN APRENDIDA\\n\\n¿QUÉ PASÓ?\\n\\nSe presentó...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>leccion_aprendida_explo_sub_carbon_cucunuba_cu...</td>\n",
       "      <td>LECCIÓN\\tAPRENDIDA\\n\\n¿QUÉ PASÓ?\\n\\nEl día 4 d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>leccion_aprendida_explo_sub_carbon_cucunuba_cu...</td>\n",
       "      <td>LECCIÓN\\tAPRENDIDA\\n\\n¿QUÉ PASÓ?\\n\\nEl día 30 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>leccion_aprendida_explo_sub_carbon_buenos_aire...</td>\n",
       "      <td>LECCIÓN APRENDIDA\\n\\n¿QUÉ PASÓ?\\n\\nSe presentó...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>leccion_aprendida_derrumbre_cali_valle_cauca_2...</td>\n",
       "      <td>¿QUÉ PASÓ?\\n\\nSe presentó un accidente minero ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                file  \\\n",
       "0  leccion_aprendida_explo_sub_carbon_el_zulia_nt...   \n",
       "1  leccion_aprendida_explo_sub_carbon_cucunuba_cu...   \n",
       "2  leccion_aprendida_explo_sub_carbon_cucunuba_cu...   \n",
       "3  leccion_aprendida_explo_sub_carbon_buenos_aire...   \n",
       "4  leccion_aprendida_derrumbre_cali_valle_cauca_2...   \n",
       "\n",
       "                                                text  \n",
       "0  LECCIÓN APRENDIDA\\n\\n¿QUÉ PASÓ?\\n\\nSe presentó...  \n",
       "1  LECCIÓN\\tAPRENDIDA\\n\\n¿QUÉ PASÓ?\\n\\nEl día 4 d...  \n",
       "2  LECCIÓN\\tAPRENDIDA\\n\\n¿QUÉ PASÓ?\\n\\nEl día 30 ...  \n",
       "3  LECCIÓN APRENDIDA\\n\\n¿QUÉ PASÓ?\\n\\nSe presentó...  \n",
       "4  ¿QUÉ PASÓ?\\n\\nSe presentó un accidente minero ...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_list = load_text_files('./../data/text/raw/')\n",
    "\n",
    "df = pd.DataFrame({\"file\": text_list.keys(), \"text\": text_list.values()})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load preprocess model\n",
    "import joblib\n",
    "MODELS_PATH = \"./models/\"\n",
    "processor = joblib.load(MODELS_PATH + \"preprocessor.pk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First step of processor pipeline is text cleaning. Clean text is needed for emotion recognition\n",
    "df[\"clean_text\"] = processor[0].transform(df.text)\n",
    "\n",
    "# Get TF-IDF matrix\n",
    "tfidf_matrix = processor[1].transform(df.clean_text)\n",
    "\n",
    "# Perform PCA for dimensionality reduction\n",
    "X = pd.DataFrame(processor[2:].transform(tfidf_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "      <th>64</th>\n",
       "      <th>65</th>\n",
       "      <th>66</th>\n",
       "      <th>67</th>\n",
       "      <th>68</th>\n",
       "      <th>69</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.136060</td>\n",
       "      <td>-0.104221</td>\n",
       "      <td>-0.233905</td>\n",
       "      <td>-0.060897</td>\n",
       "      <td>-0.252483</td>\n",
       "      <td>0.071340</td>\n",
       "      <td>-0.100001</td>\n",
       "      <td>0.103503</td>\n",
       "      <td>-0.177102</td>\n",
       "      <td>0.094348</td>\n",
       "      <td>...</td>\n",
       "      <td>0.036496</td>\n",
       "      <td>0.064023</td>\n",
       "      <td>-0.023733</td>\n",
       "      <td>-0.210630</td>\n",
       "      <td>0.028497</td>\n",
       "      <td>-0.014720</td>\n",
       "      <td>0.005116</td>\n",
       "      <td>-0.010226</td>\n",
       "      <td>0.012280</td>\n",
       "      <td>-0.019039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.347631</td>\n",
       "      <td>-0.090123</td>\n",
       "      <td>0.443983</td>\n",
       "      <td>0.030019</td>\n",
       "      <td>-0.187670</td>\n",
       "      <td>0.132380</td>\n",
       "      <td>0.010620</td>\n",
       "      <td>-0.085053</td>\n",
       "      <td>0.104718</td>\n",
       "      <td>0.005958</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.064410</td>\n",
       "      <td>-0.010888</td>\n",
       "      <td>0.018755</td>\n",
       "      <td>0.004703</td>\n",
       "      <td>0.003684</td>\n",
       "      <td>0.006932</td>\n",
       "      <td>-0.000483</td>\n",
       "      <td>-0.008082</td>\n",
       "      <td>-0.000163</td>\n",
       "      <td>-0.003191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.115998</td>\n",
       "      <td>-0.019555</td>\n",
       "      <td>-0.103137</td>\n",
       "      <td>-0.048152</td>\n",
       "      <td>-0.176678</td>\n",
       "      <td>0.057497</td>\n",
       "      <td>0.112956</td>\n",
       "      <td>-0.054637</td>\n",
       "      <td>0.213335</td>\n",
       "      <td>0.016338</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009302</td>\n",
       "      <td>0.004723</td>\n",
       "      <td>-0.001934</td>\n",
       "      <td>0.004133</td>\n",
       "      <td>-0.004232</td>\n",
       "      <td>0.001590</td>\n",
       "      <td>0.010461</td>\n",
       "      <td>-0.000843</td>\n",
       "      <td>0.001069</td>\n",
       "      <td>-0.002502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.264719</td>\n",
       "      <td>-0.137008</td>\n",
       "      <td>-0.132105</td>\n",
       "      <td>0.001269</td>\n",
       "      <td>-0.121144</td>\n",
       "      <td>0.080024</td>\n",
       "      <td>-0.004796</td>\n",
       "      <td>0.031877</td>\n",
       "      <td>-0.005656</td>\n",
       "      <td>-0.008856</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002852</td>\n",
       "      <td>0.015410</td>\n",
       "      <td>-0.022148</td>\n",
       "      <td>-0.003718</td>\n",
       "      <td>0.005559</td>\n",
       "      <td>-0.021047</td>\n",
       "      <td>-0.002660</td>\n",
       "      <td>0.005138</td>\n",
       "      <td>0.027774</td>\n",
       "      <td>0.009579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.090512</td>\n",
       "      <td>-0.034195</td>\n",
       "      <td>-0.136822</td>\n",
       "      <td>-0.090105</td>\n",
       "      <td>-0.134375</td>\n",
       "      <td>0.015920</td>\n",
       "      <td>-0.001898</td>\n",
       "      <td>0.163685</td>\n",
       "      <td>0.185808</td>\n",
       "      <td>0.074291</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008978</td>\n",
       "      <td>-0.017295</td>\n",
       "      <td>0.002429</td>\n",
       "      <td>0.013129</td>\n",
       "      <td>0.001530</td>\n",
       "      <td>-0.002752</td>\n",
       "      <td>-0.003509</td>\n",
       "      <td>0.001671</td>\n",
       "      <td>0.001095</td>\n",
       "      <td>0.000023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 70 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6   \\\n",
       "0 -0.136060 -0.104221 -0.233905 -0.060897 -0.252483  0.071340 -0.100001   \n",
       "1 -0.347631 -0.090123  0.443983  0.030019 -0.187670  0.132380  0.010620   \n",
       "2 -0.115998 -0.019555 -0.103137 -0.048152 -0.176678  0.057497  0.112956   \n",
       "3 -0.264719 -0.137008 -0.132105  0.001269 -0.121144  0.080024 -0.004796   \n",
       "4 -0.090512 -0.034195 -0.136822 -0.090105 -0.134375  0.015920 -0.001898   \n",
       "\n",
       "         7         8         9   ...        60        61        62        63  \\\n",
       "0  0.103503 -0.177102  0.094348  ...  0.036496  0.064023 -0.023733 -0.210630   \n",
       "1 -0.085053  0.104718  0.005958  ... -0.064410 -0.010888  0.018755  0.004703   \n",
       "2 -0.054637  0.213335  0.016338  ...  0.009302  0.004723 -0.001934  0.004133   \n",
       "3  0.031877 -0.005656 -0.008856  ... -0.002852  0.015410 -0.022148 -0.003718   \n",
       "4  0.163685  0.185808  0.074291  ...  0.008978 -0.017295  0.002429  0.013129   \n",
       "\n",
       "         64        65        66        67        68        69  \n",
       "0  0.028497 -0.014720  0.005116 -0.010226  0.012280 -0.019039  \n",
       "1  0.003684  0.006932 -0.000483 -0.008082 -0.000163 -0.003191  \n",
       "2 -0.004232  0.001590  0.010461 -0.000843  0.001069 -0.002502  \n",
       "3  0.005559 -0.021047 -0.002660  0.005138  0.027774  0.009579  \n",
       "4  0.001530 -0.002752 -0.003509  0.001671  0.001095  0.000023  \n",
       "\n",
       "[5 rows x 70 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cognitive Function Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
       "       6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
       "       6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
       "       6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
       "       6], dtype=int64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load model and predict cognitive function\n",
    "clf = joblib.load(MODELS_PATH + \"svm.pk\")\n",
    "y_pred = clf.predict(X)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Emotion Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With 100 most important words as input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = processor[1].get_feature_names_out()\n",
    "tfidf_scores = tfidf_matrix.toarray()\n",
    "\n",
    "important_words_per_doc = get_most_important_words(feature_names, tfidf_scores, df.file, 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_with_top_words = []\n",
    "for i in range(len(important_words_per_doc)):\n",
    "    result = {\"cognitive_function\": COGN_FUNC[y_pred[i]]}\n",
    "    result.update(get_senticnet_response(important_words_per_doc[i][\"words\"]))\n",
    "    results_with_top_words.append(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With entire clean text as input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for i in range(len(df.clean_text)):\n",
    "    result = {\"cognitive_function\": COGN_FUNC[y_pred[i]]}\n",
    "    result.update(get_senticnet_response(df.clean_text[i]))\n",
    "    results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cognitive_function': 'Praxia',\n",
       " 'status_code': 200,\n",
       " 'content': 'ecstasy (78.33%) & calmness (95.35%) [INTROSPECTION=91.85%,TEMPER=64.46%,ATTITUDE=-3.0%,SENSITIVITY=-7.1%]\\n',\n",
       " 'introspection': {'value': 0.9185, 'emotion': 'Ecstasy'},\n",
       " 'temper': {'value': 0.6446, 'emotion': 'Calmness'},\n",
       " 'attitude': {'value': -0.03, 'emotion': 'Dislike'},\n",
       " 'sensitivity': {'value': -0.071, 'emotion': 'Anxiety'}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cognitive_function': 'Praxia',\n",
       " 'status_code': 200,\n",
       " 'content': 'ecstasy (82.24%) & enthusiasm (48.48%) [INTROSPECTION=93.14%,TEMPER=50.49%,ATTITUDE=30.04%,SENSITIVITY=82.0%]\\n',\n",
       " 'introspection': {'value': 0.9314, 'emotion': 'Ecstasy'},\n",
       " 'temper': {'value': 0.5049, 'emotion': 'Calmness'},\n",
       " 'attitude': {'value': 0.3004, 'emotion': 'Acceptance'},\n",
       " 'sensitivity': {'value': 0.82, 'emotion': 'Enthusiasm'}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_with_top_words[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ontology components inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>text</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>norm_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>leccion_aprendida_explo_sub_carbon_el_zulia_nt...</td>\n",
       "      <td>LECCIÓN APRENDIDA\\n\\n¿QUÉ PASÓ?\\n\\nSe presentó...</td>\n",
       "      <td>leccion aprendido pasar presentar accidente mi...</td>\n",
       "      <td>LECCIÓN APRENDIDA ¿QUÉ PASÓ? Se presentó un ac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>leccion_aprendida_explo_sub_carbon_cucunuba_cu...</td>\n",
       "      <td>LECCIÓN\\tAPRENDIDA\\n\\n¿QUÉ PASÓ?\\n\\nEl día 4 d...</td>\n",
       "      <td>leccion aprendido pasar 4 abril ano 2020 5:00 ...</td>\n",
       "      <td>LECCIÓN APRENDIDA ¿QUÉ PASÓ? El día 4 de abril...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>leccion_aprendida_explo_sub_carbon_cucunuba_cu...</td>\n",
       "      <td>LECCIÓN\\tAPRENDIDA\\n\\n¿QUÉ PASÓ?\\n\\nEl día 30 ...</td>\n",
       "      <td>leccion aprendido pasar 30 mayo 2019 mina muni...</td>\n",
       "      <td>LECCIÓN APRENDIDA ¿QUÉ PASÓ? El día 30 de mayo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>leccion_aprendida_explo_sub_carbon_buenos_aire...</td>\n",
       "      <td>LECCIÓN APRENDIDA\\n\\n¿QUÉ PASÓ?\\n\\nSe presentó...</td>\n",
       "      <td>leccion aprendido pasar presentar accidente mi...</td>\n",
       "      <td>LECCIÓN APRENDIDA ¿QUÉ PASÓ? Se presentó un ac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>leccion_aprendida_derrumbre_cali_valle_cauca_2...</td>\n",
       "      <td>¿QUÉ PASÓ?\\n\\nSe presentó un accidente minero ...</td>\n",
       "      <td>pasar presentar accidente minero trabajador re...</td>\n",
       "      <td>¿QUÉ PASÓ? Se presentó un accidente minero cua...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                file  \\\n",
       "0  leccion_aprendida_explo_sub_carbon_el_zulia_nt...   \n",
       "1  leccion_aprendida_explo_sub_carbon_cucunuba_cu...   \n",
       "2  leccion_aprendida_explo_sub_carbon_cucunuba_cu...   \n",
       "3  leccion_aprendida_explo_sub_carbon_buenos_aire...   \n",
       "4  leccion_aprendida_derrumbre_cali_valle_cauca_2...   \n",
       "\n",
       "                                                text  \\\n",
       "0  LECCIÓN APRENDIDA\\n\\n¿QUÉ PASÓ?\\n\\nSe presentó...   \n",
       "1  LECCIÓN\\tAPRENDIDA\\n\\n¿QUÉ PASÓ?\\n\\nEl día 4 d...   \n",
       "2  LECCIÓN\\tAPRENDIDA\\n\\n¿QUÉ PASÓ?\\n\\nEl día 30 ...   \n",
       "3  LECCIÓN APRENDIDA\\n\\n¿QUÉ PASÓ?\\n\\nSe presentó...   \n",
       "4  ¿QUÉ PASÓ?\\n\\nSe presentó un accidente minero ...   \n",
       "\n",
       "                                          clean_text  \\\n",
       "0  leccion aprendido pasar presentar accidente mi...   \n",
       "1  leccion aprendido pasar 4 abril ano 2020 5:00 ...   \n",
       "2  leccion aprendido pasar 30 mayo 2019 mina muni...   \n",
       "3  leccion aprendido pasar presentar accidente mi...   \n",
       "4  pasar presentar accidente minero trabajador re...   \n",
       "\n",
       "                                           norm_text  \n",
       "0  LECCIÓN APRENDIDA ¿QUÉ PASÓ? Se presentó un ac...  \n",
       "1  LECCIÓN APRENDIDA ¿QUÉ PASÓ? El día 4 de abril...  \n",
       "2  LECCIÓN APRENDIDA ¿QUÉ PASÓ? El día 30 de mayo...  \n",
       "3  LECCIÓN APRENDIDA ¿QUÉ PASÓ? Se presentó un ac...  \n",
       "4  ¿QUÉ PASÓ? Se presentó un accidente minero cua...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from modules.text_processing import normalize\n",
    "\n",
    "df['norm_text'] = [normalize(text, False, False) for text in df.text]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "events = [get_event(text) for text in df.norm_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import owlready2 as owl\n",
    "onto = owl.get_ontology(\"./../ontology/Hourglass_COGAF_Ontology.rdf\").load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_instance = onto.Emotion(\n",
    "    \"test_emotion\", \n",
    "    introspection=results_with_top_words[0][\"introspection\"][\"value\"],\n",
    "    temper=results_with_top_words[0][\"temper\"][\"value\"],\n",
    "    attitude=results_with_top_words[0][\"attitude\"][\"value\"],\n",
    "    sensitivity=results_with_top_words[0][\"sensitivity\"][\"value\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.0075"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onto.test_emotion.introspection"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
